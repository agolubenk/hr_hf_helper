# Руководство по массовому импорту ClickUp

## Описание проблемы

Массовый импорт задач ClickUp через Celery очереди не работал корректно из-за нескольких проблем в коде.

## Исправленные проблемы

### 1. Ошибка в получении задач
**Проблема**: В строке 49 `tasks.py` был неполный вызов `service.get_tasks()`
**Решение**: Добавлена полная логика получения задач с обработкой ошибок

### 2. Логика завершения массового импорта
**Проблема**: Массовый импорт не завершался корректно
**Решение**: Добавлена проверка завершения всех задач в `import_single_task`

### 3. Обработка ошибок и логирование
**Проблема**: Недостаточное логирование и обработка ошибок
**Решение**: Добавлено подробное логирование во всех функциях

### 4. Обновление статистики
**Проблема**: Статистика не обновлялась корректно
**Решение**: Исправлена логика обновления счетчиков

## Требования для работы

### 1. Redis
```bash
# Установка Redis (Ubuntu/Debian)
sudo apt-get install redis-server

# Запуск Redis
sudo systemctl start redis-server
sudo systemctl enable redis-server

# Проверка работы
redis-cli ping
```

### 2. Celery Worker
```bash
# Запуск Celery worker
cd backend
celery -A hrhelper worker --loglevel=info

# Или с указанием очереди
celery -A hrhelper worker --loglevel=info -Q clickup_import
```

### 3. Проверка подключения
```bash
# Запуск тестового скрипта
cd backend
python test_celery_connection.py
```

## Использование массового импорта

### 1. Настройка ClickUp
1. Перейдите в настройки ClickUp интеграции
2. Укажите API токен ClickUp
3. Выберите команду, пространство и список задач

### 2. Запуск массового импорта
1. Перейдите на страницу массового импорта
2. Нажмите кнопку "Запустить массовый импорт"
3. Отслеживайте прогресс на странице прогресса

### 3. Мониторинг
- Логи Celery worker показывают детальную информацию
- Статистика обновляется в реальном времени
- При ошибках можно запустить повторный импорт

## Логирование

### Уровни логирования
- **INFO**: Общая информация о процессе
- **WARNING**: Предупреждения (например, лимит страниц)
- **ERROR**: Ошибки импорта задач
- **DEBUG**: Детальная информация (вложения, данные)

### Где смотреть логи
1. **Консоль Celery worker**: Основные логи процесса
2. **Django логи**: Ошибки в веб-интерфейсе
3. **База данных**: Статистика в модели `ClickUpBulkImport`

## Ограничения и рекомендации

### Ограничения
- Максимум 100 страниц задач (около 2000 задач)
- Задержка между задачами: 10-45 секунд
- Таймаут задачи: 30 минут

### Рекомендации
1. Запускайте массовый импорт в нерабочее время
2. Мониторьте логи на предмет ошибок
3. При большом количестве задач используйте повторный импорт
4. Регулярно очищайте кэш задач

## Устранение неполадок

### Проблема: Celery не запускается
```bash
# Проверьте Redis
redis-cli ping

# Проверьте настройки
python test_celery_connection.py
```

### Проблема: Задачи не выполняются
1. Проверьте логи Celery worker
2. Убедитесь, что Redis работает
3. Проверьте настройки ClickUp API

### Проблема: Ошибки API
1. Проверьте API токен ClickUp
2. Убедитесь в правильности ID списка
3. Проверьте права доступа к задачам

## Тестирование

### Ручное тестирование
```python
# В Django shell
from apps.clickup_int.tasks import bulk_import_clickup_tasks
from django.contrib.auth import get_user_model

User = get_user_model()
user = User.objects.first()

# Создайте запись массового импорта
from apps.clickup_int.models import ClickUpBulkImport
bulk_import = ClickUpBulkImport.objects.create(user=user, status='running')

# Запустите задачу
bulk_import_clickup_tasks.delay(user.id, bulk_import.id)
```

### Автоматическое тестирование
```bash
# Запуск тестов
python manage.py test apps.clickup_int.tests
```

## Мониторинг производительности

### Метрики для отслеживания
- Время выполнения задач
- Количество успешных/неудачных импортов
- Использование памяти Redis
- Нагрузка на ClickUp API

### Оптимизация
- Настройка количества worker'ов
- Оптимизация задержек между запросами
- Кэширование данных ClickUp

